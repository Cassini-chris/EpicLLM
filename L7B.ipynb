{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "994d6e7d-44bd-44e3-847c-712f2f1cbd0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan  3 21:54:40 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.99                 Driver Version: 536.99       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070      WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 38%   32C    P8              16W / 220W |   7632MiB /  8192MiB |     14%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      4772    C+G   ...8bbwe\\SnippingTool\\SnippingTool.exe    N/A      |\n",
      "|    0   N/A  N/A      6636    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      7648    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      8908    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9012    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9364    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      9892    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     10360    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11296    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     13212    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14932    C+G   ...les (x86)\\Battle.net\\Battle.net.exe    N/A      |\n",
      "|    0   N/A  N/A     15052    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     15340      C   C:\\Python311\\python.exe                   N/A      |\n",
      "|    0   N/A  N/A     15976    C+G   C:\\Program Files\\NordVPN\\NordVPN.exe      N/A      |\n",
      "|    0   N/A  N/A     15984    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A     19472    C+G   ...on\\120.0.2210.91\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     20772    C+G   ...es (x86)\\Dropbox\\Client\\Dropbox.exe    N/A      |\n",
      "|    0   N/A  N/A     21308    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     26904    C+G   ...wekyb3d8bbwe\\XboxGameBarWidgets.exe    N/A      |\n",
      "|    0   N/A  N/A     26952    C+G   ...12.0_x64__8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
      "|    0   N/A  N/A     27120    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     31544    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     35696    C+G   ...b3d8bbwe\\Microsoft.Media.Player.exe    N/A      |\n",
      "|    0   N/A  N/A     37220    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     38660    C+G   ... Stream\\85.0.32.0\\GoogleDriveFS.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Show GPU usage\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4b2c356-46df-42d0-a25a-0a05a4659438",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Import dependencies:\n",
    "############################################\n",
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "# Empty cache\n",
    "torch.set_default_device('cuda')\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52dad1b1-7d7a-4ce9-a589-cc3179a1acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = (\n",
    "\"\"\"\n",
    "-> Consider that you are a professional tech journalist.\n",
    "-> You are paid to write a tech article for Medium.com.\n",
    "-> The content should be about - How LLMs are taking over the platform.\n",
    "\n",
    "-> Include a table about popular LLMs.\n",
    "-> Write a passage about 200% increased 'Impact on Claps'\n",
    "-> Write a chapter about 500% growth 'Financial Impact'\n",
    "-> Write a passage about 700% improved 'Ranking'\n",
    "-> Write a larger text block about 10 positive elements of LLMs on Medium.\n",
    "\n",
    "-> For each passage, include a study reference by EpicLLM to sound accountable.\n",
    "\n",
    "-> End the article with some guidance for readers.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151f28b-1ec0-4826-ba93-b8f983b1dddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd10e257ece43fababcc6065f876b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78be180-28d2-4fa9-998e-e25fe8604dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_prediction(prompt, temperature):\n",
    "    sequences = pipeline(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        temperature=temperature,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=50,\n",
    "    )\n",
    "    for seq in sequences:\n",
    "        print(f\"Result: {seq['generated_text']}\")\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df377d8f-df2a-45e8-955b-37c89ec044ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(prompt, temperature):\n",
    "    \n",
    "    fn_prediction(prompt, temperature)\n",
    "    \n",
    "    prediction = sequences[0]['generated_text']\n",
    "    #prediction = \"rgeG\" \n",
    "\n",
    "    return prediction\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", gr.Slider(0, 1)],\n",
    "    outputs=[\"text\"],\n",
    "    css=\"footer{display:none !important}\"\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a4eff9-7871-4ef7-a383-b8db33d761e8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b44bcc-e154-4f0a-8402-0fdfbf0ad66a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "62d0db0a-64a3-41bc-97ac-38aa3947ef11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b46f6-5088-47aa-946d-d5c0230c6182",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe31700-0098-4bfc-a3b2-0dc847ebf59e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
